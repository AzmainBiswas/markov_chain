\chapter{Stationary Probability}
Consider a two-state Markov chain with transition probability matrix 
\[
    P=
    \begin{bmatrix} 
        0.35 & 0.65\\ 
        0.89 & 0.11
    \end{bmatrix} 
\]
Then 2-step transition matrix will be 
\[
    P^{2} = 
    \begin{bmatrix}
        0.7010  &  0.2990 \\ 
        0.4094  &  0.5906 
    \end{bmatrix} 
\]
Then 8-step transition matrix will be
\[
    P^{8} = 
    \begin{bmatrix}
        0.5810  &  0.4190\\ 
        0.5737  &  0.4263 
    \end{bmatrix} 
\]
Once again 12-state transition matrix is,
\[
    P^{12} = 
    \begin{bmatrix}        
        0.5782  &  0.4218\\ 
        0.5776  &  0.4224
    \end{bmatrix} 
\]
Note that The 8-step transition matrix is almost identical to 12-step transition matrix. So it seems that  $ p^{n}_{ij} $ is converging to some
value as $ n\to \infty $ that is same for all $ i $. In other words, In other word it seems to exist a limiting probability that the process will be 
in state  $ j $ after a large number of transitions, and this value is independent of initial state. This limiting probability is known as 
stationary probability and the distribution  of $ X_{j}^{n} $ as $ n\to \infty $ is known as stationary distribution.

State $ i $ is said to have  \textit{period} $ d $ if $ p^{n}_{ii} = 0 $ whenever $ n $ is not divisible by  $ d $, and  $ d $ is the largest
integer with this property. A state with period 1 is said to be \textit{aperiodic}. We denote period of $ i $ by $ d(i) $.

If state $i$ is recurrent, then it is said to be positive recurrent if, starting in state the expected time until the process returns to state $i$ 
is finite. While there exist recurrent states that an not positive recurrent (such states are
called null recurrent). Postie recurrent, aperiodic states are called \textit{ergodic}.

\begin{definition}[Stationary Distribution]
    \label{Stationary distribution}
    A probability distribution $ \{p_{j},j\ge 0\} $ is called stationary for the Markov chain if 
    \begin{equation}
        \label{1st stationary distribution}
        p_{j} = \sum_{i=0}^{\infty} p_{i}p_{ij},\ j \ge 0
    \end{equation}
    i.e. If $ \mathbf{t}=(p_{1},p_{2},\ldots,p_{j},\ldots) $ is a probability distribution vector and $ P $ is transition matrix, Then
    \begin{equation}
        \label{stationary distribution matrix}
         \mathbf{t}=\mathbf{t}P.
    \end{equation}
\end{definition}

From \cref{stationary distribution matrix} we see that 1 is a eigenvalue of transition matrix $ P $ and  $ \mathbf{t} $ is eigenvector corresponding
to 1. Since in transition matrix  such that  $ \sum_{j=0}^{\infty} p_{ij} = 1\ \forall i$ i.e. sum of all elements of row is 1,
1 must be a eigenvalue.

Now the question aeries is eigenvector corresponding to 1 is a probability vector(sum of all component in 1) or not.

\begin{theorem}[Existence and Uniqueness of Stationary Distribution]
    An irreducible aperiodic Markov chain belongs to one of the following two classes:
    \begin{enumerate}
        \item Either the state are all transient or all null recurrent; in this case $ p^{n}_{ij}\to 0 $ as $ n\to \infty \ \forall i,j $
            and there exist no stationary distribution.
        \item Or else, all states are positive recurrent, i.e.
            \begin{equation}
                \label{stationart probability}
                \pi_{j} = \lim_{n\to \infty}p_{ij}^{n}\ge 0.
            \end{equation}
            In this case, $ \{\pi_{j},j=0,1,\ldots\} $ is stationary distribution and there exist no other stationary distribution.
    \end{enumerate}
\end{theorem}
\begin{proof}
    we will first proof (2),
    we have,
    \[
        \sum_{j=0}^{M} p^{n}_{ij} \le \sum_{j=0}^{\infty} p^{n}_{ij} =1 \ \forall M.
    \]
    Letting $ n\to \infty $ we get,
    \begin{align*}
        \sum_{j=0}^{M} \pi_{j}&\le 1 \ \forall M.\\ 
        \sum_{j=0}^{\infty}\pi_{j} &\le 1.
    \end{align*}
    Now, 
     \[
         p^{n+1}_{ij} = \sum_{k=0}^{\infty} p^{n}_{ik}p_{kj}\ge \sum_{k=0}^{M} p_{ik}^{n}p_{kj} \ \forall M.
    \]
    Letting $ n\to \infty $ gives us,
    \[
        \pi_{j}\ge \sum_{k=0}^{M} \pi_{k}p_{kj} \ \forall M,
    \]
    i.e.
    \[
        \pi_{j}\ge \sum_{k=0}^{\infty} \pi_{k}p_{kj}, \ \forall j\ge 0.
    \]
    To show that the above is actually an equality, suppose the inequality is strict for some $ j $. Then we obtain,
     \[
        \sum_{j=0}^{\infty} \pi_{j}> \sum_{j=0}^{\infty} \sum_{k=0}^{\infty} \pi_{k} p_{jk} = \sum_{k=0}^{\infty} \pi_{k}\sum_{j=0}^{\infty} p_{kj} = \sum_{k=0}^{\infty} \pi_{k}.
    \]
    which is contradiction. Therefore,
    \[
        \pi_{j}=\sum_{k=0}^{\infty} \pi_{k}p_{kj}, \ \ \forall j,\ldots
    \]
    Potting $ p_{j}=\pi_{j}/\sum_{0}^{\infty} \pi_{k} $, we see that $ \{p_{j},j=0,1,2,\ldots\} $ is stationary distribution, and hence at least one 
    stationary distribution exist. Now let $ \{p_{j},j=0,1,2,\ldots\} $ be any stationary distribution. Then if $ \{p_{j},j=0,1,2,\ldots\} $ is the probabolity
    distribution of $ X_{0} $ then 
    \begin{align*}
        p_{j} &= \mathbf{P}(X_{n}=j) \\
        &= \sum_{i=0}^{\infty} \mathbf{P}(X_{n}=j|X_{0}=i)\mathbf{P}(X_{0}=i) \\
        &= \sum_{i=0}^{\infty} p^{n}_{ij}p_{i} \numberthis \label{4.3.2}
    \end{align*}
    Then, from \cref{4.3.2} we see,
    \[
        p_{j}\ge \sum_{i=0}^{M}p^{n}_{ij}p_{i} \ \ \forall M.
    \]
    Letting $ n $ and then $ M $ approach $ \infty $ we get,
    \[
        p_{j}\ge \sum_{i=0}^{\infty} \pi_{j}p_{i} = \pi_{j}.
    \]
    Now we show that $ p_{j}\le \pi_{j} $ use \cref{4.3.2} and that fact that $ p _{ij}^{n}\le 1 $ to obtain
    \[
        p_{j}\le \sum_{i=0}^{M} p^{n}_{ij}p_{i} + \sum_{i=M+1}^{\infty} p_{i} \ \forall M.
    \]
    and letting $ n\to \infty $ gives,
    \[
        p_{j}\le \sum_{i=0}^{M} \pi_{j}p_{i} + \sum_{i=M+1}^{\infty} p_{i} \ \forall M.
    \]
    Since $ \sum_{0}^{\infty} = 1 $, we obtain upon letting $ M\to \infty $ that
    \begin{equation}
        p_{j}\le \sum_{i=0}^{\infty} \pi_{j}p_{i} = \pi_{j}.
    \end{equation}

    If the state are transient or null recurrent and $ \{p_{j},j=0,1,2,\ldots\} $ is a stationary distribution, then \cref{4.3.2} hold and $ p_{ij}^{n}\to 0 $,
    which is clearly impossible. Thus, for case (1), no stationary distribution exists and the proof is complete. 
\end{proof}

\begin{remark}
    It is quite intuitive that if the process is started with the limiting probabilities, then the resultant Markov chain is stationary. 
    For in this case the Markov chain at time 0 is equivalent to an independent Markov chain with the same P matrix at time $ \infty $. 
    Hence the original chain at time $ t $ is equivalent to the second one at time $\infty + t = \infty$ therefore stationary.
\end{remark}

From \cref{stationart probability} we see that for stationary distribution vector $ \pi $ is row vector and 
\[
    P^{n}\to 
    \begin{bmatrix}
         \pi \\ 
         \pi \\ 
         \vdots \\ 
         \pi
    \end{bmatrix} 
    \ \ \ \text{as } n\to \infty
\]

\section{Reversibility}
Consider a stationary Markov Chain having transition probability $ p_{ij} $ and the stationary probabilities $ \pi_{i} $ suppose 
that we construct a sequence of states going backwards in time. That is, starting at time $ n $ consider the sequence of states 
 $ X_{n}, X_{n-1},X_{n-2},\ldots $. It is also a Markov Chain with probabilities $ p^{*}_{ij} $ define by,
 \begin{align*}
     p^{*}_{ij} &= P(X_{m}=j|X_{m+1}=i)\\ 
                &= \frac{P(X_{m+1}=i|X_{m}=j)}{P(X_{m+1}=i)} \\
                &= \frac{\pi_{j}p_{ji}}{\pi_{i}}\ \ \text{as it is in stationary state.}\numberthis \label{Reversibility 1st}
 \end{align*}
 From \cref{Reversibility 1st} we observe that probability of present state $ X_{m+1} $ given past $ X_{m},\ m>0 $ is independent of future.
Thus the reversed process is also a Markov Chain.

\begin{definition}[Time Reversible Markov Chain]
    If for any Markov chain $ p^{*}_{ij}=p_{ij} ,\ \forall\ i,\ j$ then  the Markov chain is called time Reversible.
\end{definition}
Hence the condition for time Reversibility is 
\[
    \pi_{i}p_{ij} =\pi_{j}p_{ji} \ \ \forall\ i, \ j
\]

\begin{proposition}[Reversible implies stationary]
    Suppose that $P = (qij)$ is
a transition matrix of a Markov chain that is reversible with respect to a non-negative vector 
$\mathbf{s} = (s_1, . . . , s_M)$ whose components sum to 1. Then $s$ is a stationary distribution of the chain.
\end{proposition}
\begin{proof}
    We have 
    \[
        \sum_{i=0}^{\infty} s_{i}p_{ij} = \sum_{i=0}^{\infty} s_{j}p_{ji} = s_{j}\sum_{i=1}^{\infty} p_{ji} = s_{j},
    \]
    So, $ \mathbf{s} $ is stationary.
\end{proof}

Consider a graph having a positive number $ w_{ij} $ associate with each edge $ (i,j) $ and suppose that 
a particle moves vertex to vertex in the following manner if the particle is presently at a vertex  $ i $ then 
it will move to next vertex j with probability 
 \begin{equation}
    \label{probability of weighted graph}
    p_{ij} = \frac{w_{ij}}{\sum_j w_{ij}}
\end{equation}
where $ w_{ij} =0 $ if $ (i,j) $ is not an edge of the graph. This Markov chain is called 
Random Walk on an edge weighted graph.

An irreducible positive recurrence Markov Chain is stationary if the initial state is chosen according to the
stationary probabilities. Then we say that such chain is in steady state.

\begin{proposition}
    Consider a random walk on an edge weighted graph with a finite number of vertices if this Markov chain
    is irreducible then it is in steady state, time reversible with stationary probability given by
    \[
        \pi_{i} = \frac{\sum_{j}w_{ij}}{\sum_{i}\sum_{j}w_{ij}}
    \]
\end{proposition}
\begin{proof}
    The time Reversibility equation 
    $
        \pi_{i}p_{ij} = \pi_{j}p_{ji}
    $
    and from \cref{probability of weighted graph} we get,
    $$ \frac{\pi_{i}w_{ij}}{\sum_{k}w_{ik}} = \frac{\pi_{j}w_{ji}}{\sum_{k}w_{jk}} = c $$
    or $ \pi_{i} = c \sum_{k}w_{ik} $ doing sum over all $ j $ we get the desire result.
\end{proof}

\newpage
\begin{example}
    What is the average number of steps it would take for a randomly moving knight returns to its starting point.
\end{example}
\textbf{Solution: } If a knight start from any 4(b1 , g1, b8, g8) of its starting position the process will be same as all positions are symmetric.
Let us start from b1. From b1 position knight has equal $ 1/3 $ probability to going to  a1, b3, d2. Then we consider the chess board as a graph where 
each node connected to another if a knight has a legal move between them. Then total number of node 64 and total number of edge 
$ 3 \times 8 + 2 \times 4 + 4 \times 20 + 6 \times 16 + 8\times 16 =336 $. Then stationary distribution for b1 node is 
\[
    \pi_{\text{b1}} = \frac{\sum_{j}w_{ij} }{\sum_{i}\sum_{j}w_{ij}} = \frac{3}{336} = \frac{1}{112}.
\]

Now after very long time of randomly hopping around the board the knight has probability $ \frac{1}{112} $ that it will be on the node b1. 
Then knight will take  $ 112 $ average hopping to return to b1.
